{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b5cc9334b0fd54",
   "metadata": {},
   "source": [
    "# DewanLab DeepLabCut Video Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ba0517e9b3115",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies\n",
    "#### *You can ignore any errors from tensorflow about oneDNN, cuBLAS, libnvifer, or TensorRT*"
   ]
  },
  {
   "cell_type": "code",
   "id": "e6237d61-6b6d-42e4-be5c-aedd3de70e69",
   "metadata": {
    "tags": []
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.environ['DLClight']=\"True\"\n",
    "import deeplabcut\n",
    "from pandas import pd\n",
    "print(\"Dependencies successfully imported!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa81f0dbc750efbb",
   "metadata": {},
   "source": [
    "# 2. Set User Configurables"
   ]
  },
  {
   "cell_type": "code",
   "id": "e25d6eb54e65ed1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User Configuratbles\n",
    "\"\"\"\n",
    "- video_dir: Path to EPM videos\n",
    "- video_file_extensions: list of potential video file extensions without the '.'\n",
    "- recursive_video_search: set to *True* to recursively search all folders in {video_dir} for video files\n",
    "- output_threshold: p-value above which to consider a \"good\" frame when checking quality of a labeled video\n",
    "- _shuffle: which model shuffle to use\n",
    "- _save_as_csv: whether or not to output a csv for each processed video\n",
    "- _trailpoints: number of colored points to trail behind the marked points\n",
    "\"\"\"\n",
    "\n",
    "video_dir = '/blue/adamdewan/EPM/VGLUT-20/'\n",
    "video_file_extensions = ['avi', 'mp4', 'mkv']\n",
    "recursive_video_search = False\n",
    "\n",
    "output_threshold = 0.8\n",
    "\n",
    "_shuffle = 1\n",
    "_save_as_csv = True\n",
    "_trailpoints = 0\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a85a61e186186c34",
   "metadata": {},
   "source": [
    "## 3. Get Videos"
   ]
  },
  {
   "cell_type": "code",
   "id": "20ff44cc-7966-4c42-8510-8fc806885666",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The notebook should be in the root directory of the project\n",
    "current_dir = Path.cwd()\n",
    "config_path = current_dir.joinpath('config.yaml')\n",
    "new_videos_dir = Path(video_dir)\n",
    "\n",
    "if not new_videos_dir.exists():\n",
    "    raise FileNotFoundError(f'The path {{{new_videos_dir}}} does not exist!')\n",
    "\n",
    "# Get a list of the videos in \"New Video Files\"\n",
    "video_paths = []\n",
    "\n",
    "for file_extension in video_file_extensions:\n",
    "    search_string = f'*.{file_extension}'\n",
    "    if recursive_video_search:\n",
    "        new_vids = list(new_videos_dir.rglob(search_string))\n",
    "    else:\n",
    "        new_vids = list(new_videos_dir.glob(search_string))\n",
    "\n",
    "    if len(new_vids) > 0:\n",
    "        video_paths.extend(new_vids)\n",
    "        \n",
    "video_paths = [video for video in video_paths if 'labeled' not in video.name]\n",
    "# Filter out any analyzed videos\n",
    "\n",
    "video_strings = [str(video) for video in video_paths]\n",
    "\n",
    "print(f'Found the following video(s): {video_strings}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35e46b65acd21f85",
   "metadata": {},
   "source": [
    "# 4. Process Videos"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d1fa681-9b36-4e10-9484-faf54b1b5661",
   "metadata": {
    "tags": []
   },
   "source": [
    "for video in video_paths:\n",
    "    try:\n",
    "        video_type = video.suffix\n",
    "        deeplabcut.analyze_videos(str(config_path), str(video), shuffle=_shuffle, save_as_csv=_save_as_csv, videotype=video_type)\n",
    "        deeplabcut.create_labeled_video(str(config_path), str(video), shuffle=_shuffle, videotype=video_type, trailpoints=_trailpoints)\n",
    "    except Exception as e:\n",
    "        print(f\"An error has occurred while processing video {{{video}}}\")\n",
    "        print(e)\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f87c8dd965e05d3e",
   "metadata": {},
   "source": [
    "# 5. (Optional) Analyze Analysis Output"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4207448cc7a7378",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get H5 Files\n",
    "print(f\"Percentile of frames at or above threshold ({output_threshold}) for each video:\")\n",
    "\n",
    "for video in video_paths:\n",
    "    video_stem = video.stem\n",
    "    h5_file = list(video.parent.glob(f'{video_stem}*.h5'))[0]\n",
    "\n",
    "    df = pd.read_hdf(h5_file)\n",
    "    # Get likelihood for each component, sum the values above the threshold, and calculate percentile\n",
    "    head_like_mask = (df[df.columns[2]] >= output_threshold)\n",
    "    head_like_percentile = (head_like_mask.sum() * 100) / len(head_like_mask)\n",
    "    body_like_mask = (df[df.columns[5]] >= output_threshold)\n",
    "    body_like_percentile = (body_like_mask.sum() * 100) / len(body_like_mask)\n",
    "    \n",
    "    result = f'Video: {video_stem}\\nHead Percentile: {round(head_like_percentile, 2)}%, Body Percentile: {round(body_like_percentile, 2)}%\\n'\n",
    "    print(result)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dewan Lab DLC",
   "language": "python",
   "name": "dewan_dlc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
