{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f766dffb5e85a0c",
   "metadata": {},
   "source": [
    "# DewanLab DeepLabCut Model Training\n",
    "## 1. Import Dependencies\n",
    "#### *You can ignore any errors from tensorflow about oneDNN, cuBLAS, libnvifer, or TensorRT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3adb4b-b763-4e28-b44a-d481a592ab5e",
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.environ['DLClight']=\"True\"\n",
    "os.environ['PYTHONPYCACHEPREFIX'] = './tmp'\n",
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"GPU not found!\")\n",
    "\n",
    "try:\n",
    "    import deeplabcut\n",
    "except Exception as e:\n",
    "    print(\"Error importing deeplabcut!\")\n",
    "    print(e)\n",
    "    \n",
    "print(\"Dependencies successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e5b00d2dccc6e",
   "metadata": {},
   "source": [
    "## 2. Set User Configurables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ec938ca933b60",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Training Dataset Creation\n",
    "new_shuffle_num = 1\n",
    "\n",
    "## Training Parameters\n",
    "display_iters = 10\n",
    "save_iters = 5000\n",
    "training_shuffle = 1\n",
    "\n",
    "## Video Analysis Parameters\n",
    "video_dir = './videos/Evaluation_Vid'\n",
    "video_file_extensions = ['avi', 'mp4', 'mkv']\n",
    "recursive_video_search = False\n",
    "\n",
    "novel_video_shuffle = 1\n",
    "save_as_csv = True\n",
    "trailpoints = 0\n",
    "\n",
    "output_threshold = 0.8\n",
    "\n",
    "epochs = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b91b679f95b35",
   "metadata": {},
   "source": [
    "## 3. Get Config Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af529776fa12f94",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_dir = Path.cwd()\n",
    "config_path = current_dir.joinpath('config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95029e2aea5c9d5f",
   "metadata": {},
   "source": [
    "## 4. Create New Training Dataset (If Needed)\n",
    "#### If continuing a previous round of training, this is not needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5836d050846e5b",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(config_path, num_shuffles=new_shuffle_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fedc8b685de44d",
   "metadata": {},
   "source": [
    "## 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702b040c5f71920",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "deeplabcut.train_network(config_path, shuffle=training_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605f048ea50cfc9",
   "metadata": {},
   "source": [
    "## 6: Analyze Videos\n",
    "### 6a: Get New Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0724579358488",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The notebook should be in the root directory of the project\n",
    "new_videos_dir = Path(video_dir)\n",
    "\n",
    "if not new_videos_dir.exists():\n",
    "    raise FileNotFoundError(f'The path {{{new_videos_dir}}} does not exist!')\n",
    "\n",
    "# Get a list of the videos in \"New Video Files\"\n",
    "video_paths = []\n",
    "\n",
    "for file_extension in video_file_extensions:\n",
    "    search_string = f'*.{file_extension}'\n",
    "    if recursive_video_search:\n",
    "        new_vids = list(new_videos_dir.rglob(search_string))\n",
    "    else:\n",
    "        new_vids = list(new_videos_dir.glob(search_string))\n",
    "\n",
    "    if len(new_vids) > 0:\n",
    "        video_paths.extend(new_vids)\n",
    "        \n",
    "video_paths = [video for video in video_paths if 'labeled' not in video.name]\n",
    "# Filter out any analyzed videos\n",
    "\n",
    "video_strings = [str(video) for video in video_paths]\n",
    "\n",
    "print(f'Found the following video(s): {video_strings}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1bf6514b7071c",
   "metadata": {},
   "source": [
    "### 6b: Process Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5891120b19ba7ff",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for video in video_paths:\n",
    "    try:\n",
    "        video_type = video.suffix\n",
    "        deeplabcut.analyze_videos(str(config_path), str(video), shuffle=novel_video_shuffle, save_as_csv=save_as_csv, videotype=video_type)\n",
    "        # deeplabcut.create_labeled_video(str(config_path), str(video), shuffle=novel_video_shuffle, videotype=video_type, trailpoints=_trailpoints)\n",
    "    except Exception as e:\n",
    "        print(f\"An error has occurred while processing video {{{video}}}\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0da08ebd484a7",
   "metadata": {},
   "source": [
    "## 7: (Optional) Analyze Analysis Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2078179d-1476-4725-bde0-5659bd723bd1",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get H5 Files\n",
    "print(f\"Percentile of frames at or above threshold ({output_threshold}) for each video:\\n\")\n",
    "\n",
    "_epochs = [str(epoch) for epoch in epochs]\n",
    "\n",
    "sorted_h5_files = {epoch:[] for epoch in _epochs}\n",
    "\n",
    "_h5_files = list(Path(video_dir).glob(f'*.h5'))\n",
    "\n",
    "percentiles = []\n",
    "\n",
    "for epoch in _epochs:\n",
    "    for file in _h5_files:\n",
    "        if epoch in file.stem:\n",
    "            sorted_h5_files[epoch].append(file)\n",
    "\n",
    "for epoch in _epochs:\n",
    "    print(f\"Analyzing epoch {epoch}\\n=======================\\n\")    \n",
    "    epoch_h5s = sorted_h5_files[epoch]\n",
    "    _percentiles = []\n",
    "    for h5_file in epoch_h5s:\n",
    "        df = pd.read_hdf(h5_file)\n",
    "        # Get likelihood for each component, sum the values above the threshold, and calculate percentile\n",
    "        nose_like_mask = (df[df.columns[2]] >= output_threshold)\n",
    "        nose_like_percentile = (nose_like_mask.sum() * 100) / len(nose_like_mask)\n",
    "        _percentiles.append(nose_like_percentile)\n",
    "        result = f'Video: {h5_file.stem}\\nNose Percentile: {round(nose_like_percentile, 2)}%\\n'\n",
    "        print(result)\n",
    "    if _percentiles:\n",
    "        percentiles.append(np.mean(_percentiles))\n",
    "    else:\n",
    "        percentiles.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b3cff-78fe-42c3-b435-c5d8e47fe0b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# We average the percentile for each video and plot it over the epochs\n",
    "# This gives us a rough approximation of the models performance at accurately predicting the position of the nose\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs, percentiles)\n",
    "_ = ax.set_xticks(epochs)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel(f'Average Percent of labels >= {output_threshold}')\n",
    "plt.suptitle('Performance of Model per Epoch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dewan Lab DLC",
   "language": "python",
   "name": "dewan_dlc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
